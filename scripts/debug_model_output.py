import torch
import numpy as np
from torch.utils.data import DataLoader
from dataset_build import FlightDataset, get_adjacency_matrix
from model import PhyGAT_Fixed

# é…ç½®
DEVICE = torch.device('cpu')
MODEL_PATH = 'best_model_contrast.pth'
DATA_PATH = 'dataset/flight_dataset.npy'

print("=" * 60)
print("Debugging PhyGAT Model Outputs")
print("=" * 60)

# åŠ è½½æ•°æ®
test_ds = FlightDataset(DATA_PATH, mode='test')
test_loader = DataLoader(test_ds, batch_size=4, shuffle=False)

# åŠ è½½æ¨¡å‹
adj_matrix = get_adjacency_matrix().to(DEVICE)
model = PhyGAT_Fixed(num_nodes=6, in_dim=3).to(DEVICE)
model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
model.eval()

# å–ä¸€ä¸ªbatch
x_batch, y_batch = next(iter(test_loader))
x_batch = x_batch.to(DEVICE)

print(f"\nğŸ“Š Input Data:")
print(f"   Shape: {x_batch.shape}")
print(f"   Range: [{x_batch.min():.3f}, {x_batch.max():.3f}]")
print(f"   Mean: {x_batch.mean():.3f}, Std: {x_batch.std():.3f}")

# æ¨ç†
with torch.no_grad():
    mu, log_var, attn = model(x_batch, adj_matrix, return_all_steps=True)
    sigma = torch.exp(0.5 * log_var)

print(f"\nğŸ“Š Model Outputs:")
print(f"   Mu shape: {mu.shape}")
print(f"   Mu range: [{mu.min():.3f}, {mu.max():.3f}]")
print(f"   Mu mean: {mu.mean():.3f}, std: {mu.std():.3f}")

print(f"\nğŸ“Š Uncertainty (Sigma):")
print(f"   Log_var range: [{log_var.min():.3f}, {log_var.max():.3f}]")
print(f"   Sigma range: [{sigma.min():.6f}, {sigma.max():.6f}]")
print(f"   Sigma mean: {sigma.mean():.6f}")

# å…³é”®è¯Šæ–­ï¼šSigmaæ˜¯å¦è¿‡å°
if sigma.mean() < 0.01:
    print("\nâŒ CRITICAL: Sigma is too small!")
    print("   This means the model is overconfident.")
    print("   Residual-based detection will fail.")
else:
    print("\nâœ“ Sigma is in reasonable range")

print(f"\nğŸ“Š Attention Weights:")
print(f"   Attn shape: {attn.shape}")
print(f"   Attn range: [{attn.min():.3f}, {attn.max():.3f}]")

# æ£€æŸ¥ç‰©ç†è¾¹çš„æ³¨æ„åŠ›æƒé‡
phy_edges = [(1, 3), (0, 1), (0, 2)]  # Accel->Baro, Act->Accel, Act->Gyro
attn_mean = attn.mean(dim=(0, 1))  # å¹³å‡åˆ° (N, N)

print(f"\nğŸ“Š Key Physical Edge Weights:")
for src, tgt in phy_edges:
    weight = attn_mean[tgt, src].item()
    print(f"   Edge {src}->{tgt}: {weight:.4f}")

# è®¡ç®—æ®‹å·®
residual = torch.abs(x_batch - mu)
print(f"\nğŸ“Š Residuals:")
print(f"   Range: [{residual.min():.3f}, {residual.max():.3f}]")
print(f"   Mean: {residual.mean():.3f}")

# è®¡ç®—å®é™…çš„å¼‚å¸¸å¾—åˆ†ï¼ˆæ¨¡æ‹Ÿæ£€æµ‹å™¨ï¼‰
S_res = (residual / (sigma + 1e-6)).mean(dim=(2, 3))
print(f"\nğŸ“Š Anomaly Score (S_res):")
print(f"   Range: [{S_res.min():.3f}, {S_res.max():.3f}]")
print(f"   Mean: {S_res.mean():.3f}")

if S_res.mean() < 1.0:
    print("\nâŒ CRITICAL: Anomaly scores are too low!")
    print("   With threshold=5.0, nothing will be detected.")
    print("\nğŸ’¡ SOLUTION: Need to increase sigma or change loss function")

print("\n" + "=" * 60)
print("Diagnosis Complete")
print("=" * 60)